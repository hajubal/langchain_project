{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a898547",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15f76c",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6d77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800c924",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18fd5f",
   "metadata": {},
   "source": [
    "`(3) 벡터저장소 로드`  \n",
    "- 저장해 둔 크로마 벡터저장소를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0562285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소에 저장된 문서 수: 6\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"chroma_test\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "print(f\"벡터 저장소에 저장된 문서 수: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0237e",
   "metadata": {},
   "source": [
    "## 2. LangChain LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db4266",
   "metadata": {},
   "source": [
    "### 2.1 Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6650c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]\n"
     ]
    }
   ],
   "source": [
    "# 다중 메시지 전송\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.3, \n",
    "    max_tokens=100,\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "]\n",
    "\n",
    "# 메시지 리스트를 템플릿으로 변환\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# 템플릿을 출력\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff39eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query']\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 입력 변수를 출력\n",
    "print(prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771e1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "Human: 테슬라 창업자는 누구인가요?\n"
     ]
    }
   ],
   "source": [
    "# input 값을 전달하여 프롬프트를 렌더링\n",
    "prompt_text = prompt.format(query=\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0e9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 투자자로 참여한 후, 이후 CEO로 취임하여 회사를 이끌어왔습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델에 prompt text를 직접 입력\n",
    "response = llm.invoke(prompt_text)\n",
    "\n",
    "# 모델의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27045656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]) last=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1374fccd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13cc04810>, root_client=<openai.OpenAI object at 0x127205350>, root_async_client=<openai.AsyncOpenAI object at 0x127798310>, model_name='gpt-4o-mini', temperature=0.3, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=100)\n"
     ]
    }
   ],
   "source": [
    "# LCEL 체인을 구성\n",
    "chain = prompt | llm\n",
    "\n",
    "# 체인을 출력\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a65c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'PromptInput',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# 체인의 입력 스키마를 출력\n",
    "from pprint import pprint\n",
    "pprint(chain.input_schema.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b371cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk), 마틴 에버하드(Martin Eberhard), 마크 타페닝(Mark Tarpenning), 제프 스프링어(Jeffrey Brian Straubel)입니다. 테슬라는 2003년에 설립되었으며, 엘론 머스크는 2004년에 투자자로 참여한 후 CEO로 취임하여 회사를 이끌어왔습니다. 이후 그는 테\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 1\n",
    "response = chain.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e91772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 처음 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하고, 회사의 방향성을 크게 바꾸며 현재의 테슬라로 성장시키는 데 중요한 역할을\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 2\n",
    "response = chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e0da4",
   "metadata": {},
   "source": [
    "### 2.2 Prompt + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac6ea",
   "metadata": {},
   "source": [
    "`a) 문자열 파싱 - StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de35b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 처음 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하고, 회사의 방향성을 크게 바꾸며 현재의 테슬라로 성장시키는 데 중요한 역할을', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'length', 'logprobs': None}, id='run-3631ac37-278a-46ff-a68d-0a1e8c80dc87-0', usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a73a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 처음 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하고, 회사의 방향성을 크게 바꾸며 현재의 테슬라로 성장시키는 데 중요한 역할을'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StrOutputParser - 문자열 출력을 파싱\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 출력 파서를 실행\n",
    "output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ab22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리비안(Rivian)은 2009년에 설립되었습니다. 이 회사는 전기차를 전문으로 하며, 특히 전기 픽업트럭과 SUV 모델로 주목받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "str_chain = prompt | llm  | output_parser\n",
    "\n",
    "query = \"리비안의 설립년도는 언제인가요?\"\n",
    "str_response = str_chain.invoke(query)\n",
    "\n",
    "print(str_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea86ac6",
   "metadata": {},
   "source": [
    "`b) JSON 출력 - JsonOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea62a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"창업자\": [\\n    {\\n      \"이름\": \"마틴 에버하르드\",\\n      \"역할\": \"공동 창립자\"\\n    },\\n    {\\n      \"이름\": \"마크 타페닝\",\\n      \"역할\": \"공동 창립자\"\\n    },\\n    {\\n      \"이름\": \"일론 머스크\",\\n      \"역할\": \"투자자 및 CEO\"\\n    },\\n    {\\n      \"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 34, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'length', 'logprobs': None} id='run-b8c8ab8b-2e47-4eca-916b-40eaa105ab70-0' usage_metadata={'input_tokens': 34, 'output_tokens': 100, 'total_tokens': 134}\n",
      "{'창업자': [{'이름': '마틴 에버하르드', '역할': '공동 창립자'}, {'이름': '마크 타페닝', '역할': '공동 창립자'}, {'이름': '일론 머스크', '역할': '투자자 및 CEO'}, {}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# 체인을 실행 (JSON 출력)\n",
    "json_response = chain.invoke(\"테슬라 창업자는 누구인가요? JSON 형식으로 출력해주세요.\") \n",
    "print(json_response)\n",
    "\n",
    "# 출력 파서를 실행\n",
    "json_parser_output = json_parser.invoke(json_response)\n",
    "print(json_parser_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809cf4f",
   "metadata": {},
   "source": [
    "`c) Schema 지정 - PydanticOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ec0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "PydanticOutputParser 프롬프트\n",
      "----------------------------------------\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"The title or position of the person.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "========================================\n",
      "Prompt 템플릿\n",
      "----------------------------------------\n",
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"The title or position of the person.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "Human: 테슬라 창업자는 누구인가요?\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "# Pydantic 모델을 생성\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    title: str = Field(..., description=\"The title or position of the person.\")\n",
    "\n",
    "# 출력 파서를 생성\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "print(\"========================================\")\n",
    "print(\"PydanticOutputParser 프롬프트\")\n",
    "print(\"----------------------------------------\")\n",
    "print(person_parser.get_format_instructions())\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "# Prompt 템플릿을 생성 - Pydantic 모델을 사용\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=person_parser.get_format_instructions())\n",
    "\n",
    "print(\"Prompt 템플릿\")\n",
    "print(\"----------------------------------------\")\n",
    "print(prompt.format(query=\"테슬라 창업자는 누구인가요?\"))\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8a57e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='엘론 머스크', title='CEO 및 공동 창립자')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 구성\n",
    "person_chain = prompt | llm | person_parser\n",
    "\n",
    "# 체인을 실행\n",
    "response = person_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae49f4",
   "metadata": {},
   "source": [
    "## 3. Chat Completion Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9198b73",
   "metadata": {},
   "source": [
    "`(1) stream`  \n",
    "- 입력에 대한 응답을 실시간 스트림을 생성하여 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87c23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창업자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 투자자로 참여한 후, CEO로 취임하며 회사의 성장에 큰 영향을 미쳤습니다. 이후 그는 테슬라의 가장 유명한 얼굴이 되"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for chunk in llm.stream(\"테슬라 창업자는 누구인가요?\"):\n",
    "    # 기본적으로 print 함수는 출력을 할 때마다 줄바꿈을 하지만, 줄바꿈 없이 출력하려면 end=\"\"를 사용하면 됩니다.\n",
    "    # flush=True 옵션을 사용하여 출력 버퍼를 즉시 비웁니다. 데이터를 지연 없이 즉시 출력하는 데 유용합니다.\n",
    "    print(chunk.content, end=\"\", flush=True)  \n",
    "    # time.sleep(0.1)  # 0.1초 대기 (100ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01677",
   "metadata": {},
   "source": [
    "`(2) batch`  \n",
    "- 입력 리스트에 대한 응답을 배치 단위로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1477bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "테슬라의 창립자는 마틴 에버하르드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)입니다. 이 두 사람은 2003년에 회사를 설립하였고, 이후 일론 머스크(Elon Musk)가 2004년에 투자자로 참여하면서 CEO로 취임하게 되었습니다. 일론 머스크는 테슬라의 비전과 방향성을 제시하며 회사의 성장에 큰 영향을\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "리비안(Rivian)의 창업자는 RJ 스케링(RJ Scaringe)입니다. 그는 2009년에 리비안을 설립하였으며, 전기차 제조업체로서 SUV와 픽업트럭을 주로 생산하고 있습니다. RJ 스케링은 자동차 산업의 전기화와 지속 가능한 이동 수단 개발에 큰 관심을 가지고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"테슬라의 창업자는 누구인가요?\",\n",
    "    \"리비안의 창업자는 누구인가요?\",\n",
    "]\n",
    "\n",
    "responses = llm.batch(questions)\n",
    "\n",
    "for response in responses:\n",
    "    response.pretty_print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc16413",
   "metadata": {},
   "source": [
    "## 4. Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734f412",
   "metadata": {},
   "source": [
    "`(1) RunnableParallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f21024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010')\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색기 생성\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 1}, \n",
    ")\n",
    "\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "retrieved_docs_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "pprint(retrieved_docs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcbc4d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_str': '테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010',\n",
       " 'question_str': '테슬라 창업자는 누구인가요?'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "# RunnableParrellel 구성\n",
    "runnable = RunnableParallel(\n",
    "    {\"context_str\": itemgetter(\"context\") , \"question_str\": itemgetter(\"question\")}\n",
    ")\n",
    "\n",
    "# 객체를 실행\n",
    "response = runnable.invoke({\"context\": retrieved_docs_text, \"question\": query})\n",
    "\n",
    "# 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbeb7d0",
   "metadata": {},
   "source": [
    "`(2) RunnablePassthrough`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6495f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "runnable.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458adb6e",
   "metadata": {},
   "source": [
    "`(3) RunnableLambda`\n",
    "- 정의: 파이썬의 커스텀 함수를 매핑하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def count_num_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    "    word_count=RunnableLambda(count_num_words),\n",
    ")\n",
    "\n",
    "runnable.invoke(\"테슬라 창업자는 누구인가요?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7177b",
   "metadata": {},
   "source": [
    "## 5. 전체 RAG 파이프라인 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a953ff",
   "metadata": {},
   "source": [
    "`(1) RAG 프롬프트 템플릿`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 템플릿을 생성\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "Do not use any external information or knowledge. \n",
    "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿을 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03131d4a",
   "metadata": {},
   "source": [
    "`(2) Retriever Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 검색기\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# 문서 포맷터 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# 체인 구성\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# 체인을 실행\n",
    "response = retriever_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957eeab",
   "metadata": {},
   "source": [
    "`(3) RAG Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d12f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=100)\n",
    "\n",
    "# 체인 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb9f42",
   "metadata": {},
   "source": [
    "## 6. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57035b9",
   "metadata": {},
   "source": [
    "`(1) invoke 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b207180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    response = rag_chain.invoke(message)\n",
    "    return response\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f970ba",
   "metadata": {},
   "source": [
    "`(2) stream 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b11b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    partial_message = \"\"\n",
    "    for chunk in rag_chain.stream(message):\n",
    "        if chunk is not None:\n",
    "            partial_message = partial_message + chunk\n",
    "            time.sleep(0.1)\n",
    "            yield partial_message\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env-Bme6lA2c-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
